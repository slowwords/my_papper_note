# ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models（用于去噪扩散概率模型的调节方法 ）

## Abstract

​	去噪扩散概率模型（DDPM）在无条件图像生成中表现出显著的性能。然而，由于DDPM中生成过程的随机性，生成具有所需语义的图像具有挑战性。在这项工作中，我们提出了迭代潜变量细化（ILVR），这是一种指导DDPM生成过程的方法，用于基于给定参考图像生成高质量图像。这里，DDPM中生成过程的细化使得单个DDPM能够从参考图像所指示的各种集合中采样图像。所提出的ILVR方法在控制生成的同时生成高质量图像。我们的方法的可控性允许在各种图像生成任务（如从各种下采样因子生成、多域图像翻译、绘制到图像以及使用涂鸦进行编辑）中，在不需要任何额外学习的情况下对单个DDPM进行适配。我们的代码位于：https://github.com/jychoi118/ilvr_adm. 

## 1. Introduction

​	生成模型，如生成对抗网络（GAN）[3,10,19]、归一化流[21]和变分自动编码器[42]，在图像生成中表现出显著的质量，并已应用于多种目的，如图像到图像翻译[7,11,31,32,35,47]和图像编辑[1,12,36]。

​	主要有两种方法来控制生成模型以根据需要生成图像：一种是通过为所需目的设计条件生成模型，另一种是利用性能良好的无条件生成模型 。

​	第一种方法通过在训练过程中提供所需条件来学习控制，并在各种任务上表现出出色的性能，如分割掩码条件生成[31，59]、样式转换[9，50]和修复[23，52]。第二种方法利用高质量生成模型，如StyleGAN[19，20]或BigGAN[3]。Shen等人[36]和Härkönen等人[12]通过分析预训练生成模型的潜在空间来操纵图像的语义属性，而Huh等人[16]和Zhu等人[57]通过将图像投影到潜在空间来执行图像编辑。 

​	去噪扩散概率模型（DDPM）[14，39]，一种迭代生成模型，在无条件图像生成中显示出与最新模型相当的性能。DDPM学习建模从简单分布到数据分布的马尔可夫转换，并通过顺序随机转换生成不同的样本。从DDPM获得的样本取决于简单分布的初始状态和每个跃迁。然而，控制DDPM生成具有期望语义的图像是一个挑战，因为转换的随机性生成具有不一致的高级语义的图像，即使是从相同的初始状态。 

​	在这项工作中，我们提出了一种无学习的方法，迭代潜变量求精（IL  VR），以使生成过程在良好的无条件DDPM中运行。利用给定的参考图像来细化生成过程中的每个转换。通过匹配每个潜在变量，IL  VR确保每个转换中的给定条件，从而能够从条件分布进行采样。因此，IL VR生成共享所需语义的高质量图像。 

​	我们描述了我们方法的用户可控性，这使得能够控制生成的图像与参考的语义相似性。图1（a）和图4示出了共享从粗略到精细信息的语义的样本。此外，可以从看不见的数据域中选择参考图像。从这些特性出发，我们被激励利用在单数据域到多域图像转换上学习的无条件DDPM；这是一项具有挑战性的任务，现有工作必须学习多个数据域。此外，我们将我们的方法扩展到绘制图像和使用涂鸦进行编辑（图1（c）和（d））。我们证明，我们的IL  VR能够在这些不同的任务上利用单个无条件DDPM模型，而无需任何额外的学习或模型。通过测量Fréchet起始距离（FID）和学习的感知图像块相似性（LPIPS），我们确认，我们从各种下采样因子生成的方法在保持视觉质量的同时提供了对多样性的控制。 

​	我们的论文做出了以下贡献： 

- 我们提出了IL-VR，一种通过将每个潜在变量与给定参考图像匹配来细化生成过程中的每个过渡的方法。 
- 我们研究了几个属性，这些属性允许用户对引用的语义相似性进行控制。 
- 我们证明，我们的IL VR能够在各种图像生成任务中利用无条件DDPM，包括多域图像翻译、绘制图像和使用涂鸦进行编辑。 

## 2.Background

​	

​	